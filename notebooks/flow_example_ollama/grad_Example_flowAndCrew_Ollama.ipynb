{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Install and setup ollama with models"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.175649Z",
     "iopub.status.idle": "2025-03-18T14:53:57.176088Z",
     "shell.execute_reply": "2025-03-18T14:53:57.175895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T14:53:52.797733Z",
     "iopub.status.busy": "2025-03-18T14:53:52.797264Z",
     "iopub.status.idle": "2025-03-18T14:53:52.806546Z",
     "shell.execute_reply": "2025-03-18T14:53:52.805367Z",
     "shell.execute_reply.started": "2025-03-18T14:53:52.797682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/kaggle/working\n"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/kaggle/working/\")\n",
    "\n",
    "# if not os.path.exists('/kaggle/tmp'):\n",
    "#    os.mkdir('/kaggle/tmp')\n",
    "# os.chdir('/kaggle/tmp/')\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def run(commands):\n",
    "    for command in commands:\n",
    "        with subprocess.Popen(\n",
    "            command,\n",
    "            shell=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            bufsize=1,\n",
    "        ) as sp:\n",
    "            for line in sp.stdout:\n",
    "                line = line.decode(\"utf-8\", errors=\"replace\")\n",
    "                if \"undefined reference\" in line:\n",
    "                    raise RuntimeError(\"Failed Processing.\")\n",
    "                print(line, flush=True, end=\"\")\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-18T14:53:52.810301Z",
     "iopub.status.busy": "2025-03-18T14:53:52.809861Z",
     "iopub.status.idle": "2025-03-18T14:53:57.137277Z",
     "shell.execute_reply": "2025-03-18T14:53:57.133656Z",
     "shell.execute_reply.started": "2025-03-18T14:53:52.810260Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "/kaggle/working\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/usr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ">>> Cleaning up old version at /usr/local/lib/ollama\n>>> Installing ollama to /usr/local\n>>> Downloading Linux amd64 bundle\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3a0c6fb3d37a>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;34m\"curl -fsSL https://ollama.com/install.sh | sh\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m ]\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-3a0c6fb3d37a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(commands)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommands\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"undefined reference\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"/kaggle/working/\")\n",
    "\n",
    "# if not os.path.exists('/kaggle/tmp'):\n",
    "#    os.mkdir('/kaggle/tmp')\n",
    "# os.chdir('/kaggle/tmp/')\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def run(commands):\n",
    "    for command in commands:\n",
    "        with subprocess.Popen(\n",
    "            command,\n",
    "            shell=True,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.STDOUT,\n",
    "            bufsize=1,\n",
    "        ) as sp:\n",
    "            for line in sp.stdout:\n",
    "                line = line.decode(\"utf-8\", errors=\"replace\")\n",
    "                if \"undefined reference\" in line:\n",
    "                    raise RuntimeError(\"Failed Processing.\")\n",
    "                print(line, flush=True, end=\"\")\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "\n",
    "pass\n",
    "commands = [\n",
    "    \"curl -fsSL https://ollama.com/install.sh | sh\",\n",
    "]\n",
    "run(commands)\n",
    "\n",
    "import os\n",
    "\n",
    "os.system(\"/usr/local/bin/ollama serve &\")\n",
    "os.system(\"echo 'ollama test'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Choosing the model that we will work with"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.138602Z",
     "iopub.status.idle": "2025-03-18T14:53:57.138983Z",
     "shell.execute_reply": "2025-03-18T14:53:57.138840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "commands = [\n",
    "    # \"telnet 0.0.0.0 11434\"\n",
    "    # \"ollama pull llama3\",\n",
    "    # \"ollama pull phi3\",\n",
    "    # \"ollama pull mistral\",\n",
    "    \"ollama run llama3\",\n",
    "    # \"ollama run llama3.1 \\\"create 10 sentences that ends with apple\\\"\"\n",
    "    # \"curl http://127.0.0.1:11434/api/chat -d '{\\\"model\\\": \\\"llama3\\\", \\\"stream\\\": false, \\\"messages\\\": [{ \\\"role\\\": \\\"user\\\", \\\"content\\\": \\\"create 10 sentences that ends with apple\\\" }]}'\"\n",
    "]\n",
    "run(commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.140476Z",
     "iopub.status.idle": "2025-03-18T14:53:57.141155Z",
     "shell.execute_reply": "2025-03-18T14:53:57.140968Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.system(\"curl http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# CREW AI TEST"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Edits and something we need to test :\n\n-  Add All domains , try it alone first -> Next step\n-  Add RAG System , Try it alone first  -> Next step ( Either rag from crewai or classic rag )\n-  Memory setup and its connection to rag ( Context retierver and queue and all that ( it's like another multi agent system )"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.142900Z",
     "iopub.status.idle": "2025-03-18T14:53:57.143436Z",
     "shell.execute_reply": "2025-03-18T14:53:57.143232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q crewai langchain_openai langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.144495Z",
     "iopub.status.idle": "2025-03-18T14:53:57.144885Z",
     "shell.execute_reply": "2025-03-18T14:53:57.144733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": "pip install 'crewai[tools]'\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## SETUP"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.146047Z",
     "iopub.status.idle": "2025-03-18T14:53:57.146479Z",
     "shell.execute_reply": "2025-03-18T14:53:57.146312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from crewai import LLM, Agent, Crew, Task\n",
    "from crewai.flow import Flow, listen, start\n",
    "from crewai.flow.flow import Flow, listen, start\n",
    "from crewai.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Initialize LLM\n",
    "llm = LLM(model=\"ollama/llama3\", base_url=\"http://localhost:11434\")\n",
    "\n",
    "\n",
    "domains_above = [\"filesystem\", \"users\", \"packages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.147255Z",
     "iopub.status.idle": "2025-03-18T14:53:57.147631Z",
     "shell.execute_reply": "2025-03-18T14:53:57.147489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the RAG knowledge data\n",
    "rag_knowledge = {\n",
    "    \"filesystem\": [\n",
    "        \"Moved ahmed.pdf: mv /home/user/ahmed.pdf /home/user/Documents/\",\n",
    "        \"my cat filer is in bla folder\",\n",
    "    ],\n",
    "    \"users\": [\"my password is 213214\"],\n",
    "    \"packages\": [\"Installed nginx\", \"installed ollama\"],\n",
    "}\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"rag_knowledge.json\"\n",
    "\n",
    "# Write the data to a JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(rag_knowledge, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Domain Fetcher Agent"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.148931Z",
     "iopub.status.idle": "2025-03-18T14:53:57.149714Z",
     "shell.execute_reply": "2025-03-18T14:53:57.149547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DomainAnalysis(BaseModel):\n",
    "    domains: list[str] = Field(..., description=\"List of relevant domains\")\n",
    "    confidence: float = Field(\n",
    "        ..., ge=0, le=1, description=\"Confidence score between 0 and 1\"\n",
    "    )\n",
    "\n",
    "\n",
    "domain_agent = Agent(\n",
    "    role=\"Domain Classifier\",\n",
    "    goal=\"Categorize Linux prompts into technical domains\",\n",
    "    backstory=\"Expert in Linux domain classification\",\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "domain_task = Task(\n",
    "    description=\"Analyze this Linux query: {prompt} and choose domain from the following : {domains}\",\n",
    "    expected_output=DomainAnalysis.schema_json(),\n",
    "    agent=domain_agent,\n",
    "    output_json=DomainAnalysis,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## RAG Agent"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.150909Z",
     "iopub.status.idle": "2025-03-18T14:53:57.151350Z",
     "shell.execute_reply": "2025-03-18T14:53:57.151162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_retriever(domain: str, query: str) -> str:\n",
    "    \"\"\"Retrieves context from domain-specific RAG systems.\"\"\"\n",
    "    domain = domain.lower()\n",
    "    context = rag_knowledge.get(domain)\n",
    "    return context[0]\n",
    "\n",
    "\n",
    "class ContextRetrievalResponse(BaseModel):\n",
    "    context: str = Field(..., description=\"The retrieved context related to the query\")\n",
    "\n",
    "\n",
    "# Context Retrieval Agent\n",
    "context_agent = Agent(\n",
    "    role=\"Technical Context Retriever\",\n",
    "    goal=\"Fetch relevant technical documentation and examples\",\n",
    "    backstory=\"Expert in searching and retrieving precise technical information\",\n",
    "    tools=[rag_retriever],\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "context_retrieval_task = Task(\n",
    "    description=\"Retrieve context for domain: {domain} related to: {prompt}\",\n",
    "    expected_output=ContextRetrievalResponse.schema_json(),\n",
    "    agent=context_agent,\n",
    "    output_json=ContextRetrievalResponse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## QA Agent"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.152102Z",
     "iopub.status.idle": "2025-03-18T14:53:57.152482Z",
     "shell.execute_reply": "2025-03-18T14:53:57.152340Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ValidationResult(BaseModel):\n",
    "    status: str = Field(..., description=\"Validation status: approved/needs_refinement\")\n",
    "    feedback: str = Field(..., description=\"Detailed feedback for improvement\")\n",
    "\n",
    "\n",
    "qa_agent = Agent(\n",
    "    role=\"Quality Assurance Specialist\",\n",
    "    goal=\"Ensure context relevance and accuracy\",\n",
    "    backstory=\"\"\"Meticulous validator with extensive experience in technical \n",
    "    quality assurance processes\"\"\",\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "context_validation_task = Task(\n",
    "    description=\"Validate context quality\",\n",
    "    expected_output=ValidationResult.schema_json(),\n",
    "    agent=qa_agent,\n",
    "    output_json=ValidationResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Code agent"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.153683Z",
     "iopub.status.idle": "2025-03-18T14:53:57.154043Z",
     "shell.execute_reply": "2025-03-18T14:53:57.153893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CommandOutput(BaseModel):\n",
    "    main_command: str = Field(..., description=\"Single Linux command to execute\")\n",
    "\n",
    "\n",
    "command_agent = Agent(\n",
    "    role=\"Linux Command Architect\",\n",
    "    goal=\"Generate safe and effective Linux commands\",\n",
    "    backstory=\"Experienced system administrator specializing in secure command generation\",\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "command_task = Task(\n",
    "    description=\"Generate a Linux command for: {prompt} based on these domains: {domains} and the following context : {context}\",\n",
    "    expected_output=CommandOutput.schema_json(),\n",
    "    agent=command_agent,\n",
    "    output_json=CommandOutput,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Crew 1 -> Test"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.155356Z",
     "iopub.status.idle": "2025-03-18T14:53:57.155705Z",
     "shell.execute_reply": "2025-03-18T14:53:57.155566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example crew execution\n",
    "crew = Crew(\n",
    "    agents=[domain_agent, command_agent],\n",
    "    tasks=[domain_task, command_task],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "crew_output = crew.kickoff()\n",
    "\n",
    "# Accessing the crew output\n",
    "print(f\"Raw Output: {crew_output.raw}\")\n",
    "if crew_output.json_dict:\n",
    "    print(f\"JSON Output: {json.dumps(crew_output.json_dict, indent=2)}\")\n",
    "if crew_output.pydantic:\n",
    "    print(f\"Pydantic Output: {crew_output.pydantic}\")\n",
    "print(f\"Tasks Output: {crew_output.tasks_output}\")\n",
    "print(f\"Token Usage: {crew_output.token_usage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Flow (1) for only Domain and code -> Test"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.156718Z",
     "iopub.status.idle": "2025-03-18T14:53:57.157085Z",
     "shell.execute_reply": "2025-03-18T14:53:57.156933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the flow state\n",
    "class LinuxFlowState(BaseModel):\n",
    "    prompt: str = \"\"\n",
    "    domains: list = None\n",
    "    domain_analysis: DomainAnalysis = None\n",
    "    command_output: CommandOutput = None\n",
    "\n",
    "\n",
    "class LinuxFlow(Flow[LinuxFlowState]):\n",
    "    \"\"\"Flow to execute the agents sequentially\"\"\"\n",
    "\n",
    "    @start()\n",
    "    def get_user_input(self):\n",
    "        \"\"\"Get prompt from the user\"\"\"\n",
    "        self.state.prompt = \"list all files in my directory starts with 'a'\"\n",
    "        self.state.domains = domains_above\n",
    "        return self.state\n",
    "\n",
    "    @listen(get_user_input)\n",
    "    def execute_domain_agent(self, state: LinuxFlowState):\n",
    "        \"\"\"Execute the domain agent\"\"\"\n",
    "\n",
    "        domain_response = domain_agent.execute_task(\n",
    "            domain_task,\n",
    "            context=json.dumps(\n",
    "                {\"prompt\": state.prompt, \"domains\": \", \".join(state.domains)}\n",
    "            ),\n",
    "        )\n",
    "        state.domain_analysis = DomainAnalysis.parse_raw(domain_response)\n",
    "\n",
    "        print(f\"\\nDomains identified: {state.domain_analysis.domains}\")\n",
    "        print(f\"Confidence: {state.domain_analysis.confidence}\")\n",
    "\n",
    "        return state\n",
    "\n",
    "    @listen(execute_domain_agent)\n",
    "    def execute_command_agent(self, state: LinuxFlowState):\n",
    "        \"\"\"Execute the command agent\"\"\"\n",
    "        if not state.domain_analysis:\n",
    "            print(\"No domain analysis found. Exiting.\")\n",
    "            return state\n",
    "\n",
    "        domains_str = \", \".join(state.domain_analysis.domains)\n",
    "\n",
    "        command_response = command_agent.execute_task(\n",
    "            command_task,\n",
    "            context=json.dumps(\n",
    "                {\n",
    "                    \"prompt\": state.prompt,\n",
    "                    \"domains\": \", \".join(state.domain_analysis.domains),\n",
    "                }\n",
    "            ),\n",
    "            tools=None,\n",
    "        )\n",
    "\n",
    "        state.command_output = CommandOutput.parse_raw(command_response)\n",
    "\n",
    "        print(f\"\\nGenerated Command: {state.command_output.main_command}\")\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## RUN Flow 1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.157996Z",
     "iopub.status.idle": "2025-03-18T14:53:57.158392Z",
     "shell.execute_reply": "2025-03-18T14:53:57.158245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# async def kickoff():\n",
    "#     \"\"\"Run the Linux flow\"\"\"\n",
    "#     await LinuxFlow().kickoff_async()\n",
    "\n",
    "\n",
    "# # Run the flow asynchronously for compatibility with Jupyter/Colab\n",
    "# import asyncio\n",
    "# await kickoff()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Plot flow 1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.159141Z",
     "iopub.status.idle": "2025-03-18T14:53:57.159552Z",
     "shell.execute_reply": "2025-03-18T14:53:57.159411Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "LinuxFlow().plot(\"guide_creator_flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Flow 2 Code"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.162000Z",
     "iopub.status.idle": "2025-03-18T14:53:57.162458Z",
     "shell.execute_reply": "2025-03-18T14:53:57.162293Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the flow state\n",
    "class LinuxFlowState(BaseModel):\n",
    "    prompt: str = \"\"\n",
    "    domains: list = None\n",
    "    domain_analysis: DomainAnalysis = None\n",
    "    command_output: CommandOutput = None\n",
    "    context_data: dict = None\n",
    "\n",
    "\n",
    "class LinuxFlow(Flow[LinuxFlowState]):\n",
    "    \"\"\"Flow to execute the agents sequentially\"\"\"\n",
    "\n",
    "    @start()\n",
    "    def get_user_input(self):\n",
    "        \"\"\"Get prompt from the user\"\"\"\n",
    "        self.state.prompt = \"what is my passward?\"\n",
    "        self.state.domains = domains_above\n",
    "        return self.state\n",
    "\n",
    "    @listen(get_user_input)\n",
    "    def execute_domain_agent(self, state: LinuxFlowState):\n",
    "        \"\"\"Execute the domain agent\"\"\"\n",
    "        domain_response = domain_agent.execute_task(\n",
    "            domain_task,\n",
    "            context=json.dumps(\n",
    "                {\"prompt\": state.prompt, \"domains\": \", \".join(state.domains)}\n",
    "            ),\n",
    "        )\n",
    "        state.domain_analysis = DomainAnalysis.parse_raw(domain_response)\n",
    "        print(f\"\\nDomains identified: {state.domain_analysis.domains}\")\n",
    "        return state\n",
    "\n",
    "    @listen(execute_domain_agent)\n",
    "    def retrieve_context(self, state: LinuxFlowState):\n",
    "        \"\"\"Retrieve technical context using RAG\"\"\"\n",
    "        if not state.domain_analysis:\n",
    "            return state\n",
    "\n",
    "        state.context_data = {}\n",
    "        for domain in state.domain_analysis.domains:\n",
    "            context_response = context_agent.execute_task(\n",
    "                context_retrieval_task,\n",
    "                context=json.dumps({\"domain\": domain, \"prompt\": state.prompt}),\n",
    "            )\n",
    "            state.context_data[domain] = context_response\n",
    "\n",
    "        print(\"\\nRetrieved Context:\")\n",
    "        for domain, context in state.context_data.items():\n",
    "            print(f\"- {domain}: {context[:50]}...\")\n",
    "        return state\n",
    "\n",
    "    @listen(retrieve_context)\n",
    "    def execute_command_agent(self, state: LinuxFlowState):\n",
    "        \"\"\"Generate command with domain context\"\"\"\n",
    "        if not state.domain_analysis or not state.context_data:\n",
    "            print(\"Missing domain analysis or context. Exiting.\")\n",
    "            return state\n",
    "\n",
    "        command_response = command_agent.execute_task(\n",
    "            command_task,\n",
    "            context=json.dumps(\n",
    "                {\n",
    "                    \"prompt\": state.prompt,\n",
    "                    \"domains\": \", \".join(state.domain_analysis.domains),\n",
    "                    \"context\": json.dumps(state.context_data),\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        state.command_output = CommandOutput.parse_raw(command_response)\n",
    "        print(f\"\\nFinal Command: {state.command_output.main_command}\")\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.163374Z",
     "iopub.status.idle": "2025-03-18T14:53:57.163748Z",
     "shell.execute_reply": "2025-03-18T14:53:57.163594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "async def kickoff():\n",
    "    \"\"\"Run the Linux flow\"\"\"\n",
    "    await LinuxFlow().kickoff_async()\n",
    "\n",
    "\n",
    "# Run the flow asynchronously for compatibility with Jupyter/Colab\n",
    "\n",
    "await kickoff()\n",
    "\n",
    "\n",
    "LinuxFlow().plot(\"guide_creator_flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Make a fake flow 2 -> what we can do at the end"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-18T14:53:57.164562Z",
     "iopub.status.idle": "2025-03-18T14:53:57.164909Z",
     "shell.execute_reply": "2025-03-18T14:53:57.164770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from crewai.flow.flow import Flow, listen, or_, router, start\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define Flow State\n",
    "class CustomFlowState(BaseModel):\n",
    "    prompt: str = \"\"\n",
    "    domain_output: dict = None\n",
    "    context_data: dict = None\n",
    "    qa_data: dict = None\n",
    "    code_data: dict = None\n",
    "\n",
    "\n",
    "class flow_fake(Flow[CustomFlowState]):\n",
    "    @start()\n",
    "    def user_input(self):\n",
    "        \"\"\"User provides a prompt to initiate the flow.\"\"\"\n",
    "        self.state.prompt = \"User's input prompt here\"\n",
    "        return \"domain_block\"\n",
    "\n",
    "    @listen(user_input)\n",
    "    def domain_block(self):\n",
    "        \"\"\"Processes the user prompt for domain analysis.\"\"\"\n",
    "        self.state.domain_output = {\"domains\": [\"example_domain\"]}\n",
    "        return \"router\"\n",
    "\n",
    "    @router(or_(domain_block, \"context_retriever\", \"qa_block\", \"code_block\"))\n",
    "    def router(self):\n",
    "        \"\"\"Routes the flow based on state information.\"\"\"\n",
    "        # Example routing logic: Cycle through context, QA, and Code blocks\n",
    "        if not self.state.context_data:\n",
    "            return \"context_retriever_from_route\"\n",
    "        elif not self.state.qa_data:\n",
    "            return \"qa_block_from_route\"\n",
    "        elif not self.state.code_data:\n",
    "            return \"code_block_from_route\"\n",
    "        else:\n",
    "            return \"finish_from_route\"\n",
    "\n",
    "    # Context Retriever Bidirectional Flow\n",
    "    @listen(or_(\"context_retriever_from_route\", \"rag_block\"))\n",
    "    def context_retriever(self):\n",
    "        \"\"\"Handles retrieving context and interacting with RAG.\"\"\"\n",
    "        self.state.context_data = {\"retrieved_info\": \"sample context data\"}\n",
    "        return \"router\"  # Return to router\n",
    "\n",
    "    @listen(context_retriever)\n",
    "    def rag_block(self):\n",
    "        \"\"\"Handles the RAG, Queue, and Stuff.\"\"\"\n",
    "        # Simulate RAG processing\n",
    "        return \"context_retriever\"\n",
    "\n",
    "    # QA Bidirectional Flow\n",
    "    @listen(\"qa_block_from_route\")\n",
    "    def qa_block(self):\n",
    "        \"\"\"Handles question-answering logic.\"\"\"\n",
    "        self.state.qa_data = {\"qa_response\": \"sample QA response\"}\n",
    "        return \"router\"  # Return to router\n",
    "\n",
    "    # Code Bidirectional Flow\n",
    "    @listen(\"code_block_from_route\")\n",
    "    def code_block(self):\n",
    "        \"\"\"Handles code generation tasks.\"\"\"\n",
    "        self.state.code_data = {\"code_output\": \"sample generated code\"}\n",
    "        return \"router\"  # Return to router\n",
    "\n",
    "    # Flow Completion\n",
    "    @listen(\"finish_from_route\")\n",
    "    def finish(self):\n",
    "        \"\"\"Completes the flow after all tasks are processed.\"\"\"\n",
    "\n",
    "    @listen(finish)\n",
    "    def end(self):\n",
    "        \"\"\"Finish the prompt and return what's inside\"\"\"\n",
    "        return self.state\n",
    "\n",
    "\n",
    "flow = flow_fake()\n",
    "flow.plot(\"flow_2\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}